{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "#Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "\n",
    "import sys\n",
    "sys.path.append('Write here the directory path of Code Supplementary Materil folder')\n",
    "\n",
    "#Pipelines\n",
    "from source import *\n",
    "import source.pipes as op\n",
    "\n",
    "#Sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Storing trains\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = pd.read_csv('../../data/to-ml-adult/adult.data', sep = ',', na_values =' ?').fillna('unkown')\n",
    "ds_test = pd.read_csv('../../data/to-ml-adult/adult.test', na_values =' ?').fillna('unkown')\n",
    "\n",
    "ds_final = pd.concat([ds_train, ds_test], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-age: int64, Nan: 0.000000\n",
      "1-workclass: object, Nan: 0.000000\n",
      "2-fnlwgt: int64, Nan: 0.000000\n",
      "3-education: object, Nan: 0.000000\n",
      "4-education-num: int64, Nan: 0.000000\n",
      "5-marital-status: object, Nan: 0.000000\n",
      "6-occupation: object, Nan: 0.000000\n",
      "7-relationship: object, Nan: 0.000000\n",
      "8-race: object, Nan: 0.000000\n",
      "9-sex: object, Nan: 0.000000\n",
      "10-capital-gain: int64, Nan: 0.000000\n",
      "11-capital-loss: int64, Nan: 0.000000\n",
      "12-hours-per-week: int64, Nan: 0.000000\n",
      "13-native-country: object, Nan: 0.000000\n",
      "14-income: object, Nan: 0.000000\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(ds_final.columns):\n",
    "    print(\"{0}-{1}: {2}, Nan: {3:2f}\".format(i, x, ds_final[x].dtype, 100*ds_final[x].isna().sum()/len(ds_final)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' >50K'], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_final.iloc[32560,[14]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting useful variables\n",
    "Y = ds_final.iloc[:,[14]]\n",
    "y = pd.DataFrame([1 if '>50K' in i else 0 for i in Y['income']])\n",
    "A = ds_final.iloc[:,[9]]\n",
    "X = ds_final.iloc[:,[0, 1, 4, 5, 6, 7, 8, 10, 11, 12, 13]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset\n",
    "\n",
    "Split dataset into train and test. Train will be used to fit and transform estimators, such as imputation, normalization, and predictive models. Notice that estimators will be used for transform in the data test only.\n",
    "\n",
    "For this case, 80% and 20% will be used for train and test respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_context = (y, pd.concat([X,A], axis=1, ignore_index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                int64\n",
       "workclass         object\n",
       "education-num      int64\n",
       "marital-status    object\n",
       "occupation        object\n",
       "relationship      object\n",
       "race              object\n",
       "capital-gain       int64\n",
       "capital-loss       int64\n",
       "hours-per-week     int64\n",
       "native-country    object\n",
       "sex               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, X_A = causal_context\n",
    "X_A.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-age: int64, Nan: 0.000000\n",
      "1-workclass: object, Nan: 0.000000\n",
      "2-education-num: int64, Nan: 0.000000\n",
      "3-marital-status: object, Nan: 0.000000\n",
      "4-occupation: object, Nan: 0.000000\n",
      "5-relationship: object, Nan: 0.000000\n",
      "6-race: object, Nan: 0.000000\n",
      "7-capital-gain: int64, Nan: 0.000000\n",
      "8-capital-loss: int64, Nan: 0.000000\n",
      "9-hours-per-week: int64, Nan: 0.000000\n",
      "10-native-country: object, Nan: 0.000000\n",
      "11-sex: object, Nan: 0.000000\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(X.columns):\n",
    "    print(\"{0}-{1}: {2}, Nan: {3:2f}\".format(i, x, X[x].dtype, 100*X[x].isna().sum()/len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering adult context\n",
      "Training prepro for aware\n",
      "Total of variables: 12\n",
      "Training prepro for sex\n",
      "Total of variables: 11\n",
      "Transforming test dataset aware\n",
      "Transforming test dataset sex\n",
      "\n",
      "Considering fairness context\n",
      "Training prepro for aware\n",
      "Total of variables: 12\n",
      "Training prepro for sex\n",
      "Total of variables: 11\n",
      "Transforming test dataset aware\n",
      "Transforming test dataset sex\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_scenarios = ['adult', 'fairness']\n",
    "\n",
    "for key in analysis_scenarios:\n",
    "    print('Considering {} context'.format(key))\n",
    "    Y_final, X_final = causal_context\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_final, Y_final, test_size = 0.3, stratify= Y_final, random_state = 1)\n",
    "    A_train = X_train.loc[:,['sex']]\n",
    "    A_test = X_test.loc[:,['sex']]\n",
    "\n",
    "    #Get the datasets considering X_test, y_test, and A_test\n",
    "    X_train_notaware_sex = X_train.iloc[:,:-1]\n",
    "    X_train_aware = X_train\n",
    "    \n",
    "    #Creating a dictionary for datasets\n",
    "    train_datasets = {}\n",
    "    train_datasets = {\n",
    "        'aware': X_train_aware,\n",
    "        'sex': X_train_notaware_sex\n",
    "    }\n",
    "    \n",
    "\n",
    "    #Dictionary where pickles will be stored\n",
    "    preprocessing_pickles = {}\n",
    "    preprocessing_pickles_norm = {}\n",
    "    \n",
    "    enc = 'label'\n",
    "    \n",
    "    idnumerical = [0, 2, 7, 8, 9]\n",
    "    \n",
    "    #Creating pickles for each case\n",
    "    for td in train_datasets:\n",
    "        print('Training prepro for {}'.format(td))\n",
    "        data = train_datasets[td]\n",
    "        X, pipe_nom, pipe_num, numerical_features , nominal_features = op.preprocessing(data, idnumerical=idnumerical, imputation=True, encode = enc, normalization = False)\n",
    "        preprocessing_pickles[td] = (X, pipe_nom, pipe_num)\n",
    "        \n",
    "        X, pipe_nom, pipe_num, numerical_features , nominal_features = op.preprocessing(data, idnumerical=idnumerical, imputation=True, encode = enc, normalization = True)\n",
    "        preprocessing_pickles_norm[td] = (X, pipe_nom, pipe_num)\n",
    "        \n",
    "        numerical_features.extend(nominal_features)        \n",
    "        with open('../../pipes/adult-income/'+key+'/preprocessing_features_'+td+'.pickle', 'wb') as f:\n",
    "            pickle.dump(numerical_features, f)\n",
    "            \n",
    "        print('Total of variables: {0}'.format(len(numerical_features)))\n",
    "\n",
    "    #Run following codes for storing pipelines on pickles\n",
    "    with open('../../pipes/adult-income/'+key+'/preprocessing.pickle', 'wb') as f:\n",
    "        pickle.dump(preprocessing_pickles, f)\n",
    "        \n",
    "    with open('../../pipes/adult-income/'+key+'/preprocessing_norm.pickle', 'wb') as f:\n",
    "        pickle.dump(preprocessing_pickles_norm, f)\n",
    "    \n",
    "    #Get the datasets considering X_test, y_test, and A_test\n",
    "    X_test_notaware_sex= X_test.iloc[:,:-1]\n",
    "    X_test_aware = X_test\n",
    "    \n",
    "    test_datasets = {}\n",
    "    test_datasets = {\n",
    "    'aware': X_test_aware,\n",
    "    'sex': X_test_notaware_sex,\n",
    "    }\n",
    "    \n",
    "    #Applying Preprocessing Pipelines\n",
    "    data_test_prepro = {}\n",
    "    data_test_prepro_norm = {}\n",
    "    \n",
    "    for d in preprocessing_pickles.keys():\n",
    "        print(\"Transforming test dataset {}\".format(d))\n",
    "        ds = test_datasets[d]\n",
    "        \n",
    "        _ , pnom, pnum = preprocessing_pickles[d]\n",
    "        prep_d = op.applypreprocessing(ds, pnom, pnum, idnumerical= idnumerical)\n",
    "        data_test_prepro[d] = prep_d\n",
    "\n",
    "        _ , pnom, pnum = preprocessing_pickles_norm[d]\n",
    "        prep_d = op.applypreprocessing(ds, pnom, pnum, idnumerical=idnumerical)\n",
    "        data_test_prepro_norm[d] = prep_d\n",
    "        \n",
    "    \n",
    "    with open('../../pipes/adult-income/'+key+'/preprocessing_test.pickle','wb') as f:\n",
    "        pickle.dump(data_test_prepro,f)\n",
    "    with open('../../pipes/adult-income/'+key+'/preprocessing_test_norm.pickle', 'wb') as f:\n",
    "        pickle.dump(data_test_prepro_norm, f)\n",
    "    \n",
    "    \n",
    "    y = {'train': y_train,\n",
    "         'test': y_test}\n",
    "    \n",
    "    with open('../../pipes/adult-income/'+key+'/y.pickle', 'wb') as f:\n",
    "        pickle.dump(y,f)\n",
    "    \n",
    "    A = {'train': A_train,\n",
    "         'test': A_test}\n",
    "    with open('../../pipes/adult-income/'+key+'/A.pickle','wb') as f:\n",
    "        pickle.dump(A, f)\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

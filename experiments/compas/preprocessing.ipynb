{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "#Data Handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "#Pipelines\n",
    "import source.pipes as op\n",
    "\n",
    "#Sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Storing trains\n",
    "import pickle\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_excel('../../data/to-ml-compas/compas_final.xlsx', sheet_name='two_years_recid', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-sex: object, Nan: 0.000000\n",
      "1-age: int64, Nan: 0.000000\n",
      "2-age_cat: object, Nan: 0.000000\n",
      "3-race: object, Nan: 0.000000\n",
      "4-juv_fel_count: int64, Nan: 0.000000\n",
      "5-juv_misd_count: int64, Nan: 0.000000\n",
      "6-juv_other_count: int64, Nan: 0.000000\n",
      "7-priors_count: int64, Nan: 0.000000\n",
      "8-c_days_jail: int64, Nan: 0.000000\n",
      "9-c_charge_degree: object, Nan: 0.000000\n",
      "10-is_recid: int64, Nan: 0.000000\n",
      "11-two_year_recid: int64, Nan: 0.000000\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(ds.columns):\n",
    "    print(\"{0}-{1}: {2}, Nan: {3:2f}\".format(i, x, ds[x].dtype, 100*ds[x].isna().sum()/len(ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting useful variables\n",
    "Y = ds.iloc[:,[11]]\n",
    "A = ds.iloc[:,[3]]\n",
    "X = ds.iloc[:,[0,1,2,4,5,6,7,8,9]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset\n",
    "\n",
    "Split dataset into train and test. Train will be used to fit and transform estimators, such as imputation, normalization, and predictive models. Notice that estimators will be used for transform in the data test only.\n",
    "\n",
    "For this case, 70% and 30% will be used for train and test respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_context = (Y, pd.concat([X,A], axis=1, ignore_index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-sex: object, Nan: 0.000000\n",
      "1-age: int64, Nan: 0.000000\n",
      "2-age_cat: object, Nan: 0.000000\n",
      "3-juv_fel_count: int64, Nan: 0.000000\n",
      "4-juv_misd_count: int64, Nan: 0.000000\n",
      "5-juv_other_count: int64, Nan: 0.000000\n",
      "6-priors_count: int64, Nan: 0.000000\n",
      "7-c_days_jail: int64, Nan: 0.000000\n",
      "8-c_charge_degree: object, Nan: 0.000000\n"
     ]
    }
   ],
   "source": [
    "for i, x in enumerate(X.columns):\n",
    "    print(\"{0}-{1}: {2}, Nan: {3:2f}\".format(i, x, X[x].dtype, 100*X[x].isna().sum()/len(ds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering compas context\n",
      "Training prepro for aware\n",
      "Total of variables: 10\n",
      "Training prepro for race\n",
      "Total of variables: 9\n",
      "Transforming test dataset aware\n",
      "Transforming test dataset race\n",
      "\n",
      "Considering fairness context\n",
      "Training prepro for aware\n",
      "Total of variables: 10\n",
      "Training prepro for race\n",
      "Total of variables: 9\n",
      "Transforming test dataset aware\n",
      "Transforming test dataset race\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_scenarios = ['compas', 'fairness']\n",
    "\n",
    "for key in analysis_scenarios:\n",
    "    print('Considering {} context'.format(key))\n",
    "    Y_final, X_final = causal_context\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_final, Y_final, test_size = 0.3, stratify= Y_final, random_state = 1)\n",
    "    A_train = X_train.loc[:,['race']]\n",
    "    A_test = X_test.loc[:,['race']]\n",
    "\n",
    "    #Get the datasets considering X_test, y_test, and A_test\n",
    "    X_train_notaware_race = X_train.iloc[np.array((A_train['race']=='African-American')|(A_train['race']=='Caucasian')),X_train.columns != 'race']\n",
    "    X_train_aware = X_train\n",
    "    \n",
    "    #Creating a dictionary for datasets\n",
    "    train_datasets = {}\n",
    "    train_datasets = {\n",
    "        'aware': X_train_aware,\n",
    "        'race': X_train_notaware_race,\n",
    "    }\n",
    "\n",
    "    #Dictionary where pickles will be stored\n",
    "    preprocessing_pickles = {}\n",
    "    preprocessing_pickles_norm = {}\n",
    "    \n",
    "    enc = 'label'\n",
    "    \n",
    "    idnumerical = [1, 3, 4, 5, 6,7]\n",
    "    \n",
    "    #Creating pickles for each case\n",
    "    for td in train_datasets:\n",
    "        print('Training prepro for {}'.format(td))\n",
    "        data = train_datasets[td]\n",
    "        X, pipe_nom, pipe_num, numerical_features , nominal_features = op.preprocessing(data, idnumerical=idnumerical, imputation=True, encode = enc, normalization = False)\n",
    "        preprocessing_pickles[td] = (X, pipe_nom, pipe_num)\n",
    "        \n",
    "        X, pipe_nom, pipe_num, numerical_features , nominal_features = op.preprocessing(data, idnumerical=idnumerical, imputation=True, encode = enc, normalization = True)\n",
    "        preprocessing_pickles_norm[td] = (X, pipe_nom, pipe_num)\n",
    "        \n",
    "        numerical_features.extend(nominal_features)        \n",
    "        with open('../../pipes/compas-recid/'+key+'/preprocessing_features_'+td+'.pickle', 'wb') as f:\n",
    "            pickle.dump(numerical_features, f)\n",
    "            \n",
    "        print('Total of variables: {0}'.format(len(numerical_features)))\n",
    "\n",
    "    #Run following codes for storing pipelines on pickles\n",
    "    with open('../../pipes/compas-recid/'+key+'/preprocessing.pickle', 'wb') as f:\n",
    "        pickle.dump(preprocessing_pickles, f)\n",
    "        \n",
    "    with open('../../pipes/compas-recid/'+key+'/preprocessing_norm.pickle', 'wb') as f:\n",
    "        pickle.dump(preprocessing_pickles_norm, f)\n",
    "    \n",
    "    #Get the datasets considering X_test, y_test, and A_test\n",
    "    X_test_notaware_race= X_test.iloc[np.array((A_test['race']=='African-American')|(A_test['race']=='Caucasian')),X_test.columns != 'race']\n",
    "    X_test_aware = X_test\n",
    "    \n",
    "    test_datasets = {}\n",
    "    test_datasets = {\n",
    "        'aware': X_test_aware,\n",
    "        'race': X_test_notaware_race,\n",
    "    }\n",
    "    \n",
    "    #Applying Preprocessing Pipelines\n",
    "    data_test_prepro = {}\n",
    "    data_test_prepro_norm = {}\n",
    "    \n",
    "    for d in preprocessing_pickles.keys():\n",
    "        print(\"Transforming test dataset {}\".format(d))\n",
    "        ds = test_datasets[d]\n",
    "        \n",
    "        _ , pnom, pnum = preprocessing_pickles[d]\n",
    "        prep_d = op.applypreprocessing(ds, pnom, pnum, idnumerical= idnumerical)\n",
    "        data_test_prepro[d] = prep_d\n",
    "\n",
    "        _ , pnom, pnum = preprocessing_pickles_norm[d]\n",
    "        prep_d = op.applypreprocessing(ds, pnom, pnum, idnumerical=idnumerical)\n",
    "        data_test_prepro_norm[d] = prep_d\n",
    "        \n",
    "    \n",
    "    with open('../../pipes/compas-recid/'+key+'/preprocessing_test.pickle','wb') as f:\n",
    "        pickle.dump(data_test_prepro,f)\n",
    "    with open('../../pipes/compas-recid/'+key+'/preprocessing_test_norm.pickle', 'wb') as f:\n",
    "        pickle.dump(data_test_prepro_norm, f)\n",
    "   \n",
    "    y_train_race= y_train.iloc[np.array((A_train['race']=='African-American')|(A_train['race']=='Caucasian')),:]\n",
    "    \n",
    "    y_test_race= y_test.iloc[np.array((A_test['race']=='African-American')|(A_test['race']=='Caucasian')),:]\n",
    "    \n",
    "    y = {'train_aware': y_train,\n",
    "         'train_race': y_train_race,\n",
    "         'test_aware': y_test,\n",
    "         'test_race': y_test_race,\n",
    "    }\n",
    "    \n",
    "    with open('../../pipes/compas-recid/'+key+'/y.pickle', 'wb') as f:\n",
    "        pickle.dump(y,f)\n",
    "        \n",
    "    A_train_race = A_train.iloc[np.array((A_train['race']=='African-American')|(A_train['race']=='Caucasian')), :]\n",
    "    A_test_race = A_test.iloc[np.array((A_test['race']=='African-American')|(A_test['race']=='Caucasian')), :]\n",
    "    \n",
    "    A = {'train_aware': A_train,\n",
    "         'train_race': A_train_race,\n",
    "         'test_aware': A_test,\n",
    "         'test_race': A_test_race,\n",
    "        }\n",
    "    with open('../../pipes/compas-recid/'+key+'/A.pickle','wb') as f:\n",
    "        pickle.dump(A, f)\n",
    "        \n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

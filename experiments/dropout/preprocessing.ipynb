{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "#Data Handling\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('../../')\n",
    "\n",
    "#Pipelines\n",
    "import source.pipes as op\n",
    "\n",
    "#Sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Storing trains\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('../../data/to-ml-dropout/final_dataset.csv', sep = ',', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4706, 43)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-Anio_Ingreso: int64, Nan: 0.000000\n",
      "1-Genero: int64, Nan: 0.000000\n",
      "2-Grupo_Dependencia_Colegio_F: object, Nan: 0.000000\n",
      "3-Rama_Educacional_Colegio_Grupo: object, Nan: 2.209945\n",
      "4-Ing_Bruto_Familiar_F: float64, Nan: 2.401190\n",
      "5-Preferencia_Carrera_F: float64, Nan: 1.338717\n",
      "6-Colegio_Promedio_PSU: float64, Nan: 16.192095\n",
      "7-Colegio_Total_Alumnos: float64, Nan: 16.192095\n",
      "8-Prom_Alumn_Dif: float64, Nan: 16.192095\n",
      "9-PSU_Matematica_F: float64, Nan: 3.399915\n",
      "10-PSU_Lenguaje_F: float64, Nan: 3.399915\n",
      "11-PSU_Ciencias: float64, Nan: 51.891203\n",
      "12-PSU_Historia: float64, Nan: 45.048874\n",
      "13-PSU_Hist_Ciencias: float64, Nan: 22.843179\n",
      "14-PSU_Ranking_F: float64, Nan: 2.911177\n",
      "15-Notas_Enseñanza_Media: float64, Nan: 21.121972\n",
      "16-Tipo_Ingreso: object, Nan: 17.594560\n",
      "17-Region_Residencia_Eq: object, Nan: 0.000000\n",
      "18-Participa_EDT: int64, Nan: 0.000000\n",
      "19-Participa_EDV: int64, Nan: 0.000000\n",
      "20-Participa_PAA_1Sem: int64, Nan: 0.000000\n",
      "21-Participa_PAA_2Sem: int64, Nan: 0.000000\n",
      "22-Prom_1er_Sem: float64, Nan: 0.956226\n",
      "23-Primer_Semestre_MEM: float64, Nan: 5.992350\n",
      "24-Primer_Semestre_ECO: float64, Nan: 4.717382\n",
      "25-Primer_Semestre_NEG: float64, Nan: 5.354866\n",
      "26-Primer_Semestre_IDI: float64, Nan: 27.029324\n",
      "27-Primer_Semestre_OTRO: float64, Nan: 31.555461\n",
      "28-UD_Reprobadas_Primer_Semestre: int64, Nan: 0.000000\n",
      "29-Evaluacion_Docente_Primer_Semestre: float64, Nan: 2.124947\n",
      "30-Posterga_Primer_Semestre_Final: int64, Nan: 0.000000\n",
      "31-Prom_2do_Sem: float64, Nan: 3.888653\n",
      "32-Segundo_Semestre_MEM: float64, Nan: 11.899703\n",
      "33-Segundo_Semestre_ECO: float64, Nan: 13.089673\n",
      "34-Segundo_Semestre_NEG: float64, Nan: 13.089673\n",
      "35-Segundo_Semestre_IDI: float64, Nan: 28.410540\n",
      "36-Segundo_Semestre_OTRO: float64, Nan: 7.161071\n",
      "37-UD_Reprobadas_Segundo_Semestre: float64, Nan: 3.803655\n",
      "38-Evaluacion_Docente_Segundo_Semestre: float64, Nan: 8.372291\n",
      "39-Posterga_Segundo_Semestre_F: int64, Nan: 0.000000\n",
      "40-CausalSem-11: int64, Nan: 0.000000\n",
      "41-CausalSem-12: int64, Nan: 0.000000\n",
      "42-Dropout: int64, Nan: 0.000000\n"
     ]
    }
   ],
   "source": [
    "selected = []\n",
    "for i, x in enumerate(ds.columns):\n",
    "    print(\"{0}-{1}: {2}, Nan: {3:2f}\".format(i, x, ds[x].dtype, 100*ds[x].isna().sum()/ds.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting useful variables\n",
    "Y = ds.iloc[:,[42]]\n",
    "A = ds.iloc[:,[1,2]]\n",
    "X = ds.iloc[:,range(3,42)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_dummy = pd.get_dummies(A)\n",
    "A_dummy = A_dummy.iloc[:,0:2]\n",
    "A_dummy.columns = ['gender', 'public_school']\n",
    "#So now, gender=1 means female\n",
    "A_dummy['gender'] = 1-A_dummy['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0-Rama_Educacional_Colegio_Grupo: object, Nan: 2.209945\n",
      "1-Ing_Bruto_Familiar_F: float64, Nan: 2.401190\n",
      "2-Preferencia_Carrera_F: float64, Nan: 1.338717\n",
      "3-Colegio_Promedio_PSU: float64, Nan: 16.192095\n",
      "4-Colegio_Total_Alumnos: float64, Nan: 16.192095\n",
      "5-Prom_Alumn_Dif: float64, Nan: 16.192095\n",
      "6-PSU_Matematica_F: float64, Nan: 3.399915\n",
      "7-PSU_Lenguaje_F: float64, Nan: 3.399915\n",
      "8-PSU_Ciencias: float64, Nan: 51.891203\n",
      "9-PSU_Historia: float64, Nan: 45.048874\n",
      "10-PSU_Hist_Ciencias: float64, Nan: 22.843179\n",
      "11-PSU_Ranking_F: float64, Nan: 2.911177\n",
      "12-Notas_Enseñanza_Media: float64, Nan: 21.121972\n",
      "13-Tipo_Ingreso: object, Nan: 17.594560\n",
      "14-Region_Residencia_Eq: object, Nan: 0.000000\n",
      "15-Participa_EDT: int64, Nan: 0.000000\n",
      "16-Participa_EDV: int64, Nan: 0.000000\n",
      "17-Participa_PAA_1Sem: int64, Nan: 0.000000\n",
      "18-Participa_PAA_2Sem: int64, Nan: 0.000000\n",
      "19-Prom_1er_Sem: float64, Nan: 0.956226\n",
      "20-Primer_Semestre_MEM: float64, Nan: 5.992350\n",
      "21-Primer_Semestre_ECO: float64, Nan: 4.717382\n",
      "22-Primer_Semestre_NEG: float64, Nan: 5.354866\n",
      "23-Primer_Semestre_IDI: float64, Nan: 27.029324\n",
      "24-Primer_Semestre_OTRO: float64, Nan: 31.555461\n",
      "25-UD_Reprobadas_Primer_Semestre: int64, Nan: 0.000000\n",
      "26-Evaluacion_Docente_Primer_Semestre: float64, Nan: 2.124947\n",
      "27-Posterga_Primer_Semestre_Final: int64, Nan: 0.000000\n",
      "28-Prom_2do_Sem: float64, Nan: 3.888653\n",
      "29-Segundo_Semestre_MEM: float64, Nan: 11.899703\n",
      "30-Segundo_Semestre_ECO: float64, Nan: 13.089673\n",
      "31-Segundo_Semestre_NEG: float64, Nan: 13.089673\n",
      "32-Segundo_Semestre_IDI: float64, Nan: 28.410540\n",
      "33-Segundo_Semestre_OTRO: float64, Nan: 7.161071\n",
      "34-UD_Reprobadas_Segundo_Semestre: float64, Nan: 3.803655\n",
      "35-Evaluacion_Docente_Segundo_Semestre: float64, Nan: 8.372291\n",
      "36-Posterga_Segundo_Semestre_F: int64, Nan: 0.000000\n",
      "37-CausalSem-11: int64, Nan: 0.000000\n",
      "38-CausalSem-12: int64, Nan: 0.000000\n"
     ]
    }
   ],
   "source": [
    "selected = []\n",
    "for i, x in enumerate(X.columns):\n",
    "    nan = 100*ds[x].isna().sum()/ds.shape[0]\n",
    "    if nan <=20:\n",
    "        selected.append(True)\n",
    "    else: selected.append(False)\n",
    "    print(\"{0}-{1}: {2}, Nan: {3:2f}\".format(i, x, ds[x].dtype, nan))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Dataset\n",
    "\n",
    "Split dataset into train and test. Train will be used to fit and transform estimators, such as imputation, normalization, and predictive models. We use a ratio 70/30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_context = (Y, pd.concat([X.loc[:,selected],A_dummy], axis=1, ignore_index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering dropout context\n",
      "Training prepro for aware\n",
      "Total of variables: 34\n",
      "Training prepro for unaware\n",
      "Total of variables: 32\n",
      "Training prepro for gender\n",
      "Total of variables: 33\n",
      "Training prepro for public_school\n",
      "Total of variables: 33\n",
      "Transforming test dataset aware\n",
      "Transforming test dataset unaware\n",
      "Transforming test dataset gender\n",
      "Transforming test dataset public_school\n",
      "\n",
      "Considering fairness context\n",
      "Training prepro for aware\n",
      "Total of variables: 34\n",
      "Training prepro for unaware\n",
      "Total of variables: 32\n",
      "Training prepro for gender\n",
      "Total of variables: 33\n",
      "Training prepro for public_school\n",
      "Total of variables: 33\n",
      "Transforming test dataset aware\n",
      "Transforming test dataset unaware\n",
      "Transforming test dataset gender\n",
      "Transforming test dataset public_school\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analysis_scenarios = ['dropout', 'fairness']\n",
    "\n",
    "for key in analysis_scenarios:\n",
    "    print('Considering {} context'.format(key))\n",
    "    Y_final, X_final = causal_context\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_final, Y_final, test_size = 0.3, stratify= Y_final, random_state = 1)\n",
    "    A_train = X_train.loc[:, ['gender', 'public_school']]\n",
    "    A_test = X_test.loc[:, ['gender', 'public_school']]\n",
    "    \n",
    "    #Get the datasets considering X_test, y_test, and A_test\n",
    "    X_train_notaware_gender = X_train.iloc[:, X_train.columns != 'gender']\n",
    "    X_train_notaware_school = X_train.iloc[:, X_train.columns != 'public_school']\n",
    "    X_train_unaware = X_train.iloc[:, (X_train.columns != 'gender') & (X_train.columns != 'public_school')]\n",
    "    X_train_aware = X_train\n",
    "    \n",
    "    #Creating a dictionary for datasets\n",
    "    train_datasets = {\n",
    "        'aware': X_train_aware,\n",
    "        'unaware': X_train_unaware,\n",
    "        'gender': X_train_notaware_gender,\n",
    "        'public_school': X_train_notaware_school\n",
    "    }\n",
    "\n",
    "    #Dictionary where pickles will be stored\n",
    "    preprocessing_pickles = {}\n",
    "    preprocessing_pickles_norm = {}\n",
    "    \n",
    "    enc = 'label'\n",
    "\n",
    "    #Creating pickles for each case\n",
    "    for td in train_datasets:\n",
    "        print('Training prepro for {}'.format(td))\n",
    "        data = train_datasets[td]\n",
    "        X, pipe_nom, pipe_num, numerical_features , nominal_features = op.preprocessing(data, idnumerical=None, imputation=True, encode = enc, normalization = False)\n",
    "        preprocessing_pickles[td] = (X, pipe_nom, pipe_num)\n",
    "        \n",
    "        X, pipe_nom, pipe_num, numerical_features , nominal_features = op.preprocessing(data, idnumerical=None, imputation=True, encode = enc, normalization = True)\n",
    "        preprocessing_pickles_norm[td] = (X, pipe_nom, pipe_num)\n",
    "        \n",
    "        numerical_features.extend(nominal_features)        \n",
    "        with open('../../pipes/chile-dropout/'+key+'/preprocessing_features_'+td+'.pickle', 'wb') as f:\n",
    "            pickle.dump(numerical_features, f)\n",
    "            \n",
    "        print('Total of variables: {0}'.format(len(numerical_features)))\n",
    "\n",
    "    #Run following codes for storing pipelines on pickles\n",
    "    with open('../../pipes/chile-dropout/'+key+'/preprocessing.pickle', 'wb') as f:\n",
    "        pickle.dump(preprocessing_pickles, f)\n",
    "        \n",
    "    with open('../../pipes/chile-dropout/'+key+'/preprocessing_norm.pickle', 'wb') as f:\n",
    "        pickle.dump(preprocessing_pickles_norm, f)\n",
    "    \n",
    "    #Get the datasets considering X_test, y_test, and A_test\n",
    "    X_test_notaware_gender = X_test.iloc[:, X_test.columns != 'gender']\n",
    "    X_test_notaware_school = X_test.iloc[:, X_test.columns != 'public_school']\n",
    "    X_test_unaware = X_test.iloc[:, (X_test.columns != 'gender') & (X_test.columns != 'public_school')]\n",
    "    X_test_aware = X_test\n",
    "    \n",
    "    test_datasets = {}\n",
    "    test_datasets = {\n",
    "    'aware': X_test_aware,\n",
    "    'unaware': X_test_unaware,\n",
    "    'gender': X_test_notaware_gender,\n",
    "    'public_school': X_test_notaware_school\n",
    "    }\n",
    "    \n",
    "    #Applying Preprocessing Pipelines\n",
    "    data_test_prepro = {}\n",
    "    data_test_prepro_norm = {}\n",
    "    \n",
    "    for d in preprocessing_pickles.keys():\n",
    "        print(\"Transforming test dataset {}\".format(d))\n",
    "        ds = test_datasets[d]\n",
    "        \n",
    "        _ , pnom, pnum = preprocessing_pickles[d]\n",
    "        prep_d = op.applypreprocessing(ds, pnom, pnum)\n",
    "        data_test_prepro[d] = prep_d\n",
    "\n",
    "        _ , pnom, pnum = preprocessing_pickles_norm[d]\n",
    "        prep_d = op.applypreprocessing(ds, pnom, pnum)\n",
    "        data_test_prepro_norm[d] = prep_d\n",
    "        \n",
    "    \n",
    "    with open('../../pipes/chile-dropout/'+key+'/preprocessing_test.pickle','wb') as f:\n",
    "        pickle.dump(data_test_prepro,f)\n",
    "    with open('../../pipes/chile-dropout/'+key+'/preprocessing_test_norm.pickle', 'wb') as f:\n",
    "        pickle.dump(data_test_prepro_norm, f)\n",
    "    \n",
    "    \n",
    "    y = {'train': y_train,\n",
    "         'test': y_test}\n",
    "    \n",
    "    with open('../../pipes/chile-dropout/'+key+'/y.pickle', 'wb') as f:\n",
    "        pickle.dump(y,f)\n",
    "    \n",
    "    A = {'train': A_train,\n",
    "         'test': A_test}\n",
    "    with open('../../pipes/chile-dropout/'+key+'/A.pickle','wb') as f:\n",
    "        pickle.dump(A, f)\n",
    "        \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
